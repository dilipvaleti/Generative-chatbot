{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather problem\n",
    "\n",
    "## Data\n",
    "\n",
    "This is a toy dataset of weather data and its relationship with playing golf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Play_Golf</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Windy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Humidity  Outlook  Play_Golf  Temperature  Windy\n",
       "0         1        0          0            2      0\n",
       "1         1        0          0            2      1\n",
       "2         1        1          1            2      0\n",
       "3         1        2          1            1      0\n",
       "4         0        2          1            0      0\n",
       "5         0        2          0            0      1\n",
       "6         0        1          1            0      1\n",
       "7         1        0          0            1      0\n",
       "8         0        2          0            1      1\n",
       "9         0        2          1            1      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "{\"Outlook\":     [\"R\", \"R\", \"O\", \"S\", \"S\", \"S\", \"O\", \"R\", \"S\", \"S\"],\n",
    " \"Temperature\": [\"H\", \"H\", \"H\", \"M\", \"C\", \"C\", \"C\", \"M\", \"M\", \"M\"],\n",
    " \"Humidity\":    [\"H\", \"H\", \"H\", \"H\", \"N\", \"N\", \"N\", \"H\", \"N\", \"N\"],\n",
    " \"Windy\":       [\"F\", \"T\", \"F\", \"F\", \"F\", \"T\", \"T\", \"F\", \"T\", \"F\"],\n",
    " \"Play_Golf\":   [\"N\", \"N\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"N\", \"N\", \"Y\"]\n",
    "}\n",
    ")\n",
    "\n",
    "# Mapping the letters in the dataframe to numbers\n",
    "data[\"Outlook\"] = data[\"Outlook\"].map({\"R\":0, \"O\": 1, \"S\": 2})\n",
    "data[\"Temperature\"] = data[\"Temperature\"].map({\"C\":0, \"M\": 1, \"H\": 2})\n",
    "data[\"Humidity\"] = data[\"Humidity\"].map({\"N\":0, \"H\": 1})\n",
    "data[\"Windy\"] = data[\"Windy\"].map({\"F\":0, \"T\": 1})\n",
    "data[\"Play_Golf\"] = data[\"Play_Golf\"].map({\"N\":0, \"Y\": 1})\n",
    "\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing information gain for weather data\n",
    "\n",
    "Here we would manually compute information gain for different features. We will also validate that our computation is correct by computing information gain for two edge cases (i.e. a pure split, random split). We will see that a pure split gives an `information gain=1` and random split gives `information gain=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking information gain with toy data\n",
      "\tInformation Gain for Toy data is: Actual (1.0) Expected (1.0)\n",
      "\tInformation Gain for Toy data is: Actual (0.0) Expected (0.0)\n",
      "\n",
      "Checking information gain with actual data\n",
      "\tEntropy for Play_Golf is: 1.0\n",
      "\n",
      "\tInformation gain for feature Outlook is : 0.5145247027726657\n",
      "\tInformation gain for feature Temperature is : 0.0490224995673062\n",
      "\tInformation gain for feature Humidity is : 0.02904940554533142\n",
      "\tInformation gain for feature Windy is : 0.12451124978365313\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_infogain(data, feature, label_col_name):\n",
    "    \"\"\"\n",
    "    This function computes the information gain\n",
    "    IG(Y|X) = H(Y) - H(Y|X)\n",
    "    data: A pd.DataFrame container all data\n",
    "    grouped_data: A groupby object that groups Play_GOLF value counts by some feature\n",
    "    \"\"\"\n",
    "\n",
    "    grouped_data = data.groupby(feature)[label_col_name].value_counts()\n",
    "    \n",
    "    h_y = compute_entropy(data[label_col_name])\n",
    "    h_y_given_x = 0\n",
    "    #print(grouped_data)\n",
    "    for k in grouped_data.keys():\n",
    "        # k is a tuple, which has the feature index followed by label index (groupby object)\n",
    "        k_f, k_y = k\n",
    "        h_y_given_x += (grouped_data[k_f][k_y].sum()*1.0/data.shape[0])* compute_entropy_with_counts(grouped_data[k_f])\n",
    "    \n",
    "    return h_y - h_y_given_x\n",
    "    \n",
    "def compute_entropy(ser):\n",
    "    \"\"\"\n",
    "    This function computes the entropy\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    counts = ser.value_counts()\n",
    "    for k in ser.unique():\n",
    "        #print(k)\n",
    "        total += -(counts[k]*1.0/ser.shape[0])*np.log2(counts[k]*1.0/ser.shape[0])\n",
    "        \n",
    "    return total\n",
    "\n",
    "def compute_entropy_with_counts(data_counts):\n",
    "    \"\"\"\n",
    "    This function computes the entropy\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for k in data_counts:\n",
    "        total += -(k*1.0/data_counts.sum())*np.log2(k*1.0/data_counts.sum())\n",
    "       \n",
    "    return total\n",
    "\n",
    "## Making sure computations are correct\n",
    "\n",
    "## The answer should be 1.0 because the data will be perfectly split to 0s and 1s\n",
    "## by splitting according to x\n",
    "print('Checking information gain with toy data')\n",
    "toy_data = pd.DataFrame({'x':[0,0,0,0,1,1,1,1], 'y':[0,0,0,0,1,1,1,1]})\n",
    "print('\\tInformation Gain for Toy data is: Actual ({}) Expected ({})'.format(\n",
    "    compute_infogain(toy_data, 'x', \"y\"), 1.0\n",
    "))\n",
    "\n",
    "## The answer should be 0.0 because the data will be random after splitting according to x\n",
    "toy_data = pd.DataFrame({'x':[1,0,1,0,1,0,1,0], 'y':[0,0,0,0,1,1,1,1]})\n",
    "print('\\tInformation Gain for Toy data is: Actual ({}) Expected ({})\\n'.format(\n",
    "    compute_infogain(toy_data, 'x', \"y\"), 0.0\n",
    "))\n",
    "\n",
    "print('Checking information gain with actual data')\n",
    "print('\\tEntropy for Play_Golf is: {}\\n'.format(compute_entropy(data[\"Play_Golf\"])))\n",
    "\n",
    "for col in [\"Outlook\", \"Temperature\", \"Humidity\", \"Windy\"]:\n",
    "    print('\\tInformation gain for feature {} is : {}'.format(col, compute_infogain(data, col, \"Play_Golf\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the tree\n",
    "\n",
    "Let us now create a decision tree, which uses information gain to find the best split. The algorithm is as follows:\n",
    "\n",
    "1. Find a feature to split data (based on the information gain)\n",
    "2. Split/Partition data into `n` sets depending on the unique values\n",
    "3. For each partition\n",
    "  * If termination condition is not met\n",
    "    * Repeat step 1\n",
    "    * Repeat step 2\n",
    "    \n",
    "    \n",
    "Following code is adopted from [this repository](https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb). This code is a more general version, where the tree can have an arbitrary number of children. \n",
    "\n",
    "**Note** : This tree model cannot work with continuous features, but only discrete/categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree related objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "\n",
    "    def __init__(self, feature, value, data=None, children=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.data = data\n",
    "        self.children = children\n",
    "\n",
    "    def set_parent(self, parent):\n",
    "        self.parent = parent\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "class LeafNode:\n",
    "    \n",
    "    def __init__(self, data, label_column):\n",
    "        self.prediction = data[label_column].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree related helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(feature, values, data_to_split):\n",
    "    \"\"\"\n",
    "    Splits the data such that each dataframe in the returned list \n",
    "    has the same value for the selected feature\n",
    "    \"\"\"\n",
    "    data_splits = {}\n",
    "    for v in values:\n",
    "        true_data = data_to_split.loc[data_to_split[feature]==v,:]\n",
    "        data_splits[v] = true_data\n",
    "    return data_splits\n",
    "\n",
    "\n",
    "def find_best_feature(data_to_split, features, label_column):\n",
    "    \"\"\"\n",
    "    This function finds the best feature to split that maximizes\n",
    "    the information gain for a given dataframe\n",
    "    \"\"\"\n",
    "    #feature_infogain_tuples = []\n",
    "    max_feature, max_ig = None, -1e10\n",
    "    for f in features:\n",
    "        #partitions = partition_data(f, set(data_to_split[f].tolist()), data_to_split)\n",
    "        ig = compute_infogain(data_to_split, f, label_column)\n",
    "        if ig >= max_ig:\n",
    "            max_feature = f\n",
    "            max_ig = ig\n",
    "    return max_feature, max_ig\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive tree building method\n",
    "\n",
    "In this `build_tree` function, I use two termination conditions to terminate the growth of a branch\n",
    "* The number of datapoints in a branch is less than `min_leaf_count`\n",
    "* The information gained by splitting is less than `ig_tol`\n",
    "* The depth of a branch is greater than `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data_to_split, label_column, features, best_feature=None, value=None, depth=0, min_leaf_count=3, ig_tol=1e-10, max_depth=5):\n",
    "    \"\"\"\n",
    "    This Function computes the sub tree recursively. This is a more general tree model\n",
    "    where there can be arbitrary number of children for a given node\n",
    "    :param data_to_split: pd.DataFrame\n",
    "    :param label_column: str (Column name of Y)\n",
    "    :param features: list of str (Column names of X)\n",
    "    :param best_feature: str (previous best feature fed recursively to build the tree)\n",
    "    :param value: int (previous value of the feature fed recursively)\n",
    "    :param depth: int (previous depth of the tree fed recursively)\n",
    "    :param min_leaf_count: int (minimum number of datapoints in a leaf)\n",
    "    :param ig_tol: float (information gain tolerance to make a split)\n",
    "    :param max_depth: int (maximum depth allowed in the tree)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sanity check (ig_tol needs to be > 0). Otherwise\n",
    "    # data having the same label before and after the split \n",
    "    # (information gain =0) will create many useless branches\n",
    "    if ig_tol<=0.0:\n",
    "        print('ig_tol needs to be > 0')\n",
    "        return\n",
    "    \n",
    "    # Termination condition 1 (minimum count on leaf)\n",
    "    if data_to_split.shape[0]<=min_leaf_count:\n",
    "        print('Too little data. Terminating growth ...')\n",
    "        children = [LeafNode(data_to_split, label_column)]\n",
    "        return DecisionNode(best_feature, value, data_to_split, children=children)\n",
    "    \n",
    "    # Finding the next best feature to split the data on\n",
    "    next_best_feature, infogain = find_best_feature(data_to_split, features, label_column)\n",
    "    feature_unique_values = list(set(data_to_split[next_best_feature].tolist()))\n",
    "    \n",
    "    # Termination condition 2 (minimum information gain)\n",
    "    if infogain < ig_tol or next_best_feature is None:\n",
    "        print('Too little information gain. Terminating growth ...')\n",
    "        children = [LeafNode(data_to_split, label_column)]\n",
    "        return DecisionNode(best_feature, value, data_to_split, children=children)\n",
    "    \n",
    "    next_depth = depth + 1\n",
    "    \n",
    "    # Termination condition 3 (depth)\n",
    "    if depth >= max_depth:\n",
    "        print('Too deep. Terminating growth ...')\n",
    "        children = [LeafNode(data_to_split, label_column)]\n",
    "        return DecisionNode(best_feature, value, data_to_split, children=children)\n",
    "    \n",
    "    print('Choosing {} as the best feature with {} information gain at depth {}'.format(next_best_feature, infogain, next_depth))\n",
    "    # Partition the data according to the selected features values\n",
    "    parts_dict = partition_data(next_best_feature, feature_unique_values, data_to_split)\n",
    "    \n",
    "    # For each partition create a child, where child recursively calls build_tree\n",
    "    children = []\n",
    "    \n",
    "    for attr, p in parts_dict.items():\n",
    "        print('\\tCreating child node {}={} having {} data points...'.format(next_best_feature, attr, p.shape[0]))\n",
    "        children.append(build_tree(p, label_column, features, next_best_feature, attr, next_depth, min_leaf_count, ig_tol, max_depth))\n",
    "        \n",
    "    # Return the node\n",
    "    return DecisionNode(best_feature, value, data_to_split, children=children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running, building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing Outlook as the best feature with 0.5145247027726657 information gain at depth 1\n",
      "\tCreating child node Outlook=0 having 3 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Outlook=1 having 2 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Outlook=2 having 5 data points...\n",
      "Choosing Windy as the best feature with 0.9709505944546686 information gain at depth 2\n",
      "\tCreating child node Windy=0 having 3 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Windy=1 having 2 data points...\n",
      "Too little data. Terminating growth ...\n"
     ]
    }
   ],
   "source": [
    "# Returns the root node\n",
    "my_tree = build_tree(data, \"Play_Golf\", [\"Outlook\", \"Temperature\", \"Humidity\", \"Windy\"], ig_tol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the tree\n",
    "The tree is printed such that the lines with the same indentation are at the same depth in the tree. For example the tree,\n",
    "\n",
    "`-------------N1\n",
    "       0--> /  \\ <--1\n",
    "           N2  N3\n",
    "     0--> / \\ <--1\n",
    "         N4 N5            `\n",
    "         \n",
    "will be printed as,\n",
    "\n",
    "`Root\n",
    " N1 = 0\n",
    "  N2 = 0\n",
    "   N4\n",
    "  N2 = 1\n",
    "   N5\n",
    " N1 = 1\n",
    "  N3     `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the decision tree ...\n",
      "  Root\n",
      "   Node Outlook = 0\n",
      "    Leaf Prediction:  0\n",
      "   Node Outlook = 1\n",
      "    Leaf Prediction:  1\n",
      "   Node Outlook = 2\n",
      "    Node Windy = 0\n",
      "     Leaf Prediction:  1\n",
      "    Node Windy = 1\n",
      "     Leaf Prediction:  0\n"
     ]
    }
   ],
   "source": [
    "print('Printing the decision tree ...')\n",
    "def print_tree(node, spacing=''):\n",
    "    \"\"\"\n",
    "    This function recursively prints the tree with indentation\n",
    "    \"\"\"\n",
    "    spacing += ' '\n",
    "    \n",
    "    if isinstance(node, LeafNode):\n",
    "        print(spacing, 'Leaf Prediction: ', node.prediction)\n",
    "        return \n",
    "    \n",
    "    if node.feature==None and node.value==None:\n",
    "        print(spacing, \"Root\")\n",
    "    else:\n",
    "        print(spacing, \"Node\",node.feature, '=', node.value)\n",
    "        \n",
    "    for c in node.children:\n",
    "        print_tree(c, spacing)\n",
    "\n",
    "\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_datapoint(test_point, my_tree):\n",
    "    \"\"\"\n",
    "    This function computes the prediction for a given data point\n",
    "    \"\"\"\n",
    "    \n",
    "    for c in my_tree.children:\n",
    "        # If we came to a leaf node, return the prediction given by the leaf node\n",
    "        if isinstance(c, LeafNode):\n",
    "            return c.prediction\n",
    "        \n",
    "        # If the feature value matches the value of the data point, keep diving\n",
    "        if test_point[c.feature] == c.value:\n",
    "            return predict_datapoint(test_point, c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for {'Temperature': 2, 'Windy': 0, 'Outlook': 0, 'Humidity': 0}\n",
      "\tPredicted label (Play_Golf): False\n"
     ]
    }
   ],
   "source": [
    "datapoint = {\"Outlook\": 0, \"Humidity\": 0, \"Temperature\": 2, \"Windy\": 0}\n",
    "print('Predicted label for {}'.format(datapoint))\n",
    "\n",
    "pred = predict_datapoint(datapoint, my_tree)\n",
    "print('\\tPredicted label (Play_Golf): {}'.format(False if pred==0 else True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the disguised king\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Castle</th>\n",
       "      <th>Gold_Tooth</th>\n",
       "      <th>Greedy</th>\n",
       "      <th>Is_King</th>\n",
       "      <th>Slow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Castle  Gold_Tooth  Greedy  Is_King  Slow\n",
       "0       1           1       0        1     1\n",
       "1       0           1       1        1     0\n",
       "2       0           1       0        1     1\n",
       "3       1           1       1        1     0\n",
       "4       1           1       0        1     1\n",
       "5       0           1       1        0     0\n",
       "6       0           1       0        0     1\n",
       "7       1           0       1        0     0\n",
       "8       0           1       0        0     1\n",
       "9       0           1       1        0     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king_data = pd.DataFrame(\n",
    "{\"Castle\":     [\"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\"],\n",
    " \"Slow\":       [\"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\"],\n",
    " \"Gold_Tooth\": [\"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\"],\n",
    " \"Greedy\":  [\"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\"],\n",
    " \"Is_King\":    [\"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\"]\n",
    "}\n",
    ")\n",
    "\n",
    "king_data[\"Castle\"] = king_data[\"Castle\"].map({\"N\":0, \"Y\": 1})\n",
    "king_data[\"Slow\"] = king_data[\"Slow\"].map({\"N\":0, \"Y\": 1})\n",
    "king_data[\"Greedy\"] = king_data[\"Greedy\"].map({\"N\":0, \"Y\": 1})\n",
    "king_data[\"Gold_Tooth\"] = king_data[\"Gold_Tooth\"].map({\"N\":0, \"Y\": 1})\n",
    "king_data[\"Is_King\"] = king_data[\"Is_King\"].map({\"N\":0, \"Y\": 1})\n",
    "\n",
    "king_data.head(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Building tree ========== \n",
      "\n",
      "Choosing Castle as the best feature with 0.12451124978365313 information gain at depth 1\n",
      "\tCreating child node Castle=0 having 6 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Castle=1 having 4 data points...\n",
      "Choosing Gold_Tooth as the best feature with 0.8112781244591328 information gain at depth 2\n",
      "\tCreating child node Gold_Tooth=0 having 1 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Gold_Tooth=1 having 3 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\n",
      " ========== Printing tree ==========\n",
      "  Root\n",
      "   Node Castle = 0\n",
      "    Leaf Prediction:  0\n",
      "   Node Castle = 1\n",
      "    Node Gold_Tooth = 0\n",
      "     Leaf Prediction:  0\n",
      "    Node Gold_Tooth = 1\n",
      "     Leaf Prediction:  1\n"
     ]
    }
   ],
   "source": [
    "print('='*10, 'Building tree', '='*10, '\\n')\n",
    "king_tree = build_tree(king_data, \"Is_King\", [\"Castle\", \"Slow\", \"Greedy\", \"Gold_Tooth\"], ig_tol=1e-3)\n",
    "print('\\n','='*10, 'Printing tree', '='*10)\n",
    "print_tree(king_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and regularization\n",
    "\n",
    "Let's see what happens when we increase the amount of data without regularization. You will see how that leads to a massive tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Building tree ========== \n",
      "\n",
      "Choosing Castle as the best feature with 0.09845845811405807 information gain at depth 1\n",
      "\tCreating child node Castle=0 having 29 data points...\n",
      "Choosing Gold_Tooth as the best feature with 0.00480527328186231 information gain at depth 2\n",
      "\tCreating child node Gold_Tooth=0 having 4 data points...\n",
      "Choosing Slow as the best feature with 0.12255624891826566 information gain at depth 3\n",
      "\tCreating child node Slow=0 having 3 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Slow=1 having 1 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Gold_Tooth=1 having 25 data points...\n",
      "Choosing Slow as the best feature with 0.005646310646669206 information gain at depth 3\n",
      "\tCreating child node Slow=0 having 18 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Slow=1 having 7 data points...\n",
      "Choosing Greedy as the best feature with 0.19811742113040343 information gain at depth 4\n",
      "\tCreating child node Greedy=0 having 6 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Greedy=1 having 1 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Castle=1 having 21 data points...\n",
      "Choosing Slow as the best feature with 0.14026267083366217 information gain at depth 2\n",
      "\tCreating child node Slow=0 having 7 data points...\n",
      "Choosing Gold_Tooth as the best feature with 0.2916919971380597 information gain at depth 3\n",
      "\tCreating child node Gold_Tooth=0 having 2 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Gold_Tooth=1 having 5 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Slow=1 having 14 data points...\n",
      "Choosing Gold_Tooth as the best feature with 0.04957603870374783 information gain at depth 3\n",
      "\tCreating child node Gold_Tooth=0 having 3 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Gold_Tooth=1 having 11 data points...\n",
      "Choosing Greedy as the best feature with 0.06297794600548684 information gain at depth 4\n",
      "\tCreating child node Greedy=0 having 4 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Greedy=1 having 7 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\n",
      " ========== Printing tree ==========\n",
      "  Root\n",
      "   Node Castle = 0\n",
      "    Node Gold_Tooth = 0\n",
      "     Node Slow = 0\n",
      "      Leaf Prediction:  0\n",
      "     Node Slow = 1\n",
      "      Leaf Prediction:  0\n",
      "    Node Gold_Tooth = 1\n",
      "     Node Slow = 0\n",
      "      Leaf Prediction:  0\n",
      "     Node Slow = 1\n",
      "      Node Greedy = 0\n",
      "       Leaf Prediction:  0\n",
      "      Node Greedy = 1\n",
      "       Leaf Prediction:  1\n",
      "   Node Castle = 1\n",
      "    Node Slow = 0\n",
      "     Node Gold_Tooth = 0\n",
      "      Leaf Prediction:  0\n",
      "     Node Gold_Tooth = 1\n",
      "      Leaf Prediction:  1\n",
      "    Node Slow = 1\n",
      "     Node Gold_Tooth = 0\n",
      "      Leaf Prediction:  1\n",
      "     Node Gold_Tooth = 1\n",
      "      Node Greedy = 0\n",
      "       Leaf Prediction:  1\n",
      "      Node Greedy = 1\n",
      "       Leaf Prediction:  1\n"
     ]
    }
   ],
   "source": [
    "aug_king_data = pd.DataFrame(\n",
    "{\"Castle\":     [\n",
    "    \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\",\n",
    "    \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\",\n",
    "    \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\",\n",
    "    \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\",\n",
    "    \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\",\n",
    "],\n",
    " \"Slow\":       [\n",
    "     \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\",\n",
    "     \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\",\n",
    "     \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\",\n",
    "     \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\",\n",
    "     \"Y\", \"N\", \"N\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\"\n",
    " ],\n",
    " \"Gold_Tooth\": [\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\",\n",
    "     \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\"\n",
    " ],\n",
    " \"Greedy\":  [\n",
    "     \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\",\n",
    "     \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\",\n",
    "     \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"N\", \"Y\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\"\n",
    " ],\n",
    " \"Is_King\":    [\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\",\n",
    "     \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\"\n",
    " ]\n",
    "}\n",
    ")\n",
    "\n",
    "aug_king_data[\"Castle\"] = aug_king_data[\"Castle\"].map({\"N\":0, \"Y\": 1})\n",
    "aug_king_data[\"Slow\"] = aug_king_data[\"Slow\"].map({\"N\":0, \"Y\": 1})\n",
    "aug_king_data[\"Greedy\"] = aug_king_data[\"Greedy\"].map({\"N\":0, \"Y\": 1})\n",
    "aug_king_data[\"Gold_Tooth\"] = aug_king_data[\"Gold_Tooth\"].map({\"N\":0, \"Y\": 1})\n",
    "aug_king_data[\"Is_King\"] = aug_king_data[\"Is_King\"].map({\"N\":0, \"Y\": 1})\n",
    "\n",
    "print('='*10, 'Building tree', '='*10, '\\n')\n",
    "aug_king_tree = build_tree(aug_king_data, \"Is_King\", [\"Castle\", \"Slow\", \"Greedy\", \"Gold_Tooth\"],min_leaf_count=1, ig_tol=1e-20,max_depth=10)\n",
    "print('\\n','='*10, 'Printing tree', '='*10)\n",
    "print_tree(aug_king_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree model with regularization\n",
    "We set `min_leaf_count`=5, `ig_tol`=1e-2 and `max_depth`=3 as regularization steps. You can see that the new tree is way simpler and interpretable than the previous tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Building tree ========== \n",
      "\n",
      "Choosing Castle as the best feature with 0.09845845811405807 information gain at depth 1\n",
      "\tCreating child node Castle=0 having 29 data points...\n",
      "Too little information gain. Terminating growth ...\n",
      "\tCreating child node Castle=1 having 21 data points...\n",
      "Choosing Slow as the best feature with 0.14026267083366217 information gain at depth 2\n",
      "\tCreating child node Slow=0 having 7 data points...\n",
      "Choosing Gold_Tooth as the best feature with 0.2916919971380597 information gain at depth 3\n",
      "\tCreating child node Gold_Tooth=0 having 2 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Gold_Tooth=1 having 5 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Slow=1 having 14 data points...\n",
      "Choosing Gold_Tooth as the best feature with 0.04957603870374783 information gain at depth 3\n",
      "\tCreating child node Gold_Tooth=0 having 3 data points...\n",
      "Too little data. Terminating growth ...\n",
      "\tCreating child node Gold_Tooth=1 having 11 data points...\n",
      "Too deep. Terminating growth ...\n",
      "\n",
      " ========== Printing tree ==========\n",
      "  Root\n",
      "   Node Castle = 0\n",
      "    Leaf Prediction:  0\n",
      "   Node Castle = 1\n",
      "    Node Slow = 0\n",
      "     Node Gold_Tooth = 0\n",
      "      Leaf Prediction:  0\n",
      "     Node Gold_Tooth = 1\n",
      "      Leaf Prediction:  1\n",
      "    Node Slow = 1\n",
      "     Node Gold_Tooth = 0\n",
      "      Leaf Prediction:  1\n",
      "     Node Gold_Tooth = 1\n",
      "      Leaf Prediction:  1\n"
     ]
    }
   ],
   "source": [
    "print('='*10, 'Building tree', '='*10, '\\n')\n",
    "aug_king_tree = build_tree(aug_king_data, \"Is_King\", [\"Castle\", \"Slow\", \"Greedy\", \"Gold_Tooth\"],min_leaf_count=5, ig_tol=1e-2,max_depth=3)\n",
    "print('\\n','='*10, 'Printing tree', '='*10)\n",
    "print_tree(aug_king_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "* Change the LeafNode, so that it outputs the prediction probabilities in addition to the class\n",
    "* John thought of a new feature, which is the `distance traveled in a day`. Rewrite (below) a decision tree that can work with continuous values (you can start with a simple method such as binning) to discrete values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
